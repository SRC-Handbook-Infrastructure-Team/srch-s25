## Case Study: Timnit Gebru's Google Exit
Timnit Gebru’s forced exit from Google serves as a notable example of why holding an individual developer accountable does little to remedy the underlying systemic issues that produce biased AI. The case shows that it is the institution’s opaque review processes, profit-driven priorities, and entrenched cultural biases that create conditions ripe for discriminatory outcomes. Gebru’s experience, where her legitimate criticisms of internal practices and calls for transparency were used to scapegoat her as “problematic”, affirms that responsibility must lie with governments, large organizations, and social institutions. Therefore, lawmakers and regulators should focus on ensuring that companies deploy robust safeguards in their automated systems to address the root causes of bias across diverse use cases, from financial decision-making to hiring practices, instead of imposing blanket liability on individual developers.

[Further Reading](https://www.axios.com/2021/02/19/google-tweaks-diversity-research-policies-following-inquiry)